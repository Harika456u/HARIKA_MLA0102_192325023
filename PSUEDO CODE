BFS (Breadth-First Search) – Pseudocode:
BFS(Graph, startNode):
    create an empty Queue Q
    mark startNode as visited
    enqueue startNode into Q
    while Q is not empty:
        currentNode ← dequeue Q
        print currentNode
        for each adjacentNode of currentNode:
            if adjacentNode is not visited:
                mark adjacentNode as visited
                enqueue adjacentNode into Q

DFS:
DFS (Depth-First Search) – Pseudocode:
DFS(Graph, startNode):
    mark startNode as visited
    print startNode

    for each adjacentNode of startNode:
        if adjacentNode is not visited:
            DFS(Graph, adjacentNode)

MIN-MAx:
MINIMAX(node, depth, isMaxPlayer):
    IF node is a terminal node OR depth = 0:
        RETURN value of node
    IF isMaxPlayer = TRUE:
        bestValue ← -∞
        FOR each child of node:
            value ← MINIMAX(child, depth - 1, FALSE)
            bestValue ← MAX(bestValue, value)
        RETURN bestValue
    ELSE:
        bestValue ← +∞
        FOR each child of node:
            value ← MINIMAX(child, depth - 1, TRUE)
            bestValue ← MIN(bestValue, value)
        RETURN bestValue

Alpha–Beta Pruning – Pseudocode:
ALPHABETA(node, depth, α, β, isMaxPlayer):
    IF node is a terminal node OR depth = 0:
        RETURN value of node
    IF isMaxPlayer = TRUE:
        value ← -∞
        FOR each child of node:
            value ← MAX(value,
                         ALPHABETA(child, depth - 1, α, β, FALSE))
            α ← MAX(α, value)
            IF α ≥ β:
                BREAK   // β cut-off (pruning)
        RETURN value
    ELSE:
        value ← +∞
        FOR each child of node:
            value ← MIN(value,
                         ALPHABETA(child, depth - 1, α, β, TRUE))
            β ← MIN(β, value)
            IF β ≤ α:
                BREAK   // α cut-off (pruning)
        RETURN value

DECISION TREE:
ID3(Dataset S, Attribute list A, Target attribute C)
1. If all tuples in S belong to the same class C
      Return a leaf node with that class
2. If A is empty
      Return a leaf node with the majority class in S
3. Compute Entropy of S:
      Entropy(S) = − Σ p(c) log2 p(c)
4. For each attribute Ai in A
      a) Partition S based on values of Ai
      b) Compute Entropy for each partition
      c) Compute Information Gain:
            IG(S, Ai) = Entropy(S) − Σ (|Sv| / |S|) × Entropy(Sv)
5. Select attribute Amax with maximum Information Gain
6. Create a decision node that splits on Amax
7. For each value v of Amax
      a) Create subset Sv of S where Amax = v
      b) If Sv is empty
            Attach a leaf node with majority class of S
         Else
            Recursively call:
            ID3(Sv, A − {Amax}, C)
8. Return the constructed decision tree

Algorithm Greedy_Best_First_Search(start, goal)

1. Create an OPEN list (priority queue)
2. Create a CLOSED list (visited)

3. Insert start into OPEN with priority = h(start)

4. While OPEN is not empty
      a. Remove node n from OPEN with lowest h(n)
      b. If n = goal
            return SUCCESS and path
      c. Add n to CLOSED
      d. For each successor s of n
            If s not in OPEN and not in CLOSED
                  Set parent of s = n
                  Insert s into OPEN with priority = h(s)

5. Return FAILURE


Algorithm Water_Jug_Problem(X, Y, target)

1. Initialize state (0, 0)
2. Create a queue
3. Create a visited set

4. Enqueue initial state (0, 0)

5. While queue is not empty
      a. Dequeue current state (a, b)
      b. If a = target or b = target
            return SUCCESS

      c. Generate all possible next states:
            - Fill Jug1: (X, b)
            - Fill Jug2: (a, Y)
            - Empty Jug1: (0, b)
            - Empty Jug2: (a, 0)
            - Pour Jug1 → Jug2
            - Pour Jug2 → Jug1

      d. For each new state
            If not visited
                  Mark visited
                  Enqueue state

6. Return FAILURE

Algorithm A_Star_Search(start, goal)

1. Create OPEN list (priority queue)
2. Create CLOSED list

3. g(start) = 0
4. f(start) = g(start) + h(start)
5. Insert start into OPEN

6. While OPEN is not empty
      a. Remove node n from OPEN with lowest f(n)
      b. If n = goal
            return SUCCESS and path
      c. Add n to CLOSED

      d. For each successor s of n
            temp_g = g(n) + cost(n, s)

            If s not in OPEN and not in CLOSED
                  parent(s) = n
                  g(s) = temp_g
                  f(s) = g(s) + h(s)
                  Insert s into OPEN

            Else if temp_g < g(s)
                  parent(s) = n
                  g(s) = temp_g
                  f(s) = g(s) + h(s)

7. Return FAILURE
